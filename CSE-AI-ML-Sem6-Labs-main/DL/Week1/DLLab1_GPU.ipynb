{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9951484b-3908-4d5c-a743-822075b9dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1126, 0.1884, 0.9518],\n",
      "        [0.7832, 0.9079, 0.2917]], device='cuda:0')\n",
      "tensor([[0.2767, 0.2121, 0.4268],\n",
      "        [0.6724, 0.6687, 0.8829]], device='cuda:0')\n",
      "tensor([[0.4773, 1.0419],\n",
      "        [0.5337, 1.3912]], device='cuda:0')\n",
      "tensor(0.9518, device='cuda:0') tensor(0.8829, device='cuda:0')\n",
      "tensor(0.1126, device='cuda:0') tensor(0.2121, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(5, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "rand() received an invalid combination of arguments - got (tuple, seed=int), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(t1_g\u001b[38;5;241m.\u001b[39margmin(),t2_g\u001b[38;5;241m.\u001b[39margmin())\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#Random tensor with shape(1,1,1,10) and remove all dimensions with shape 1\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m t3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m), seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(t3\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m t3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(t3)\n",
      "\u001b[0;31mTypeError\u001b[0m: rand() received an invalid combination of arguments - got (tuple, seed=int), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Create 2 random tensors of size (2,3) and send them to GPU\n",
    "t1 = torch.rand(2,3)\n",
    "t2 = torch.rand(2,3)\n",
    "t1_g = t1.to(\"cuda\")\n",
    "t2_g = t2.to(\"cuda\")\n",
    "print(t1_g)\n",
    "print(t2_g)\n",
    "\n",
    "#Perform Matrix multiplication\n",
    "tmul = torch.matmul(t1_g,t2_g.T)\n",
    "print(tmul)\n",
    "\n",
    "#Get max and min values of the 2 random tensors\n",
    "print(t1_g.max(),t2_g.max())\n",
    "print(t1_g.min(),t2_g.min())\n",
    "\n",
    "#Get max and min index values of the 2 random tensors\n",
    "print(t1_g.argmax(),t2_g.argmax())\n",
    "print(t1_g.argmin(),t2_g.argmin())\n",
    "\n",
    "#Random tensor with shape(1,1,1,10) and remove all dimensions with shape 1\n",
    "t3 = torch.rand(1,1,1,10)\n",
    "print(t3.shape)\n",
    "t3 = torch.squeeze(t3)\n",
    "print(t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb96ed9-39e2-4435-b1f1-36000c67b7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([2, 3, 3])\n",
      "tensor([[[1, 1, 1],\n",
      "         [2, 2, 2],\n",
      "         [3, 3, 3]],\n",
      "\n",
      "        [[4, 4, 4],\n",
      "         [5, 5, 5],\n",
      "         [6, 6, 6]]])\n",
      "Reshaping\n",
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4],\n",
      "        [5, 5, 5],\n",
      "        [6, 6, 6]])\n",
      "\n",
      "Viewing\n",
      "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6])\n",
      "\n",
      "Stacking\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Squeeze\n",
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 1, 2, 2])\n",
      "\n",
      "Unsqueeze\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]])\n",
      "Permute\n",
      "tensor([[[1, 4],\n",
      "         [1, 4],\n",
      "         [1, 4]],\n",
      "\n",
      "        [[2, 5],\n",
      "         [2, 5],\n",
      "         [2, 5]],\n",
      "\n",
      "        [[3, 6],\n",
      "         [3, 6],\n",
      "         [3, 6]]])\n",
      "\n",
      "Indexing\n",
      "tensor([[4, 4, 4],\n",
      "        [5, 5, 5],\n",
      "        [6, 6, 6]])\n",
      "tensor([4, 4, 4])\n",
      "tensor(4)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "[[1 1 1]\n",
      " [1 1 1]]\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]])\n",
      "\n",
      "Tensor 1 for multiplication: \n",
      "tensor([[0.0247, 0.1476, 0.6705, 0.8659, 0.2355, 0.6708, 0.7682],\n",
      "        [0.7263, 0.8218, 0.9096, 0.2081, 0.7402, 0.2257, 0.3265],\n",
      "        [0.2271, 0.8944, 0.2639, 0.7469, 0.6514, 0.3985, 0.3908],\n",
      "        [0.6894, 0.2707, 0.6189, 0.3170, 0.8056, 0.8848, 0.8371],\n",
      "        [0.3856, 0.7961, 0.2167, 0.5503, 0.6441, 0.8453, 0.3532],\n",
      "        [0.4963, 0.4711, 0.1917, 0.3913, 0.7194, 0.2300, 0.1270],\n",
      "        [0.5776, 0.7809, 0.9127, 0.6664, 0.2423, 0.7962, 0.3391]])\n",
      "Tensor 2 for multiplication: \n",
      "tensor([[0.3830, 0.2116, 0.3729, 0.5969, 0.6896, 0.3008, 0.9128]])\n",
      "After multiplication: \n",
      "tensor([[1.8730],\n",
      "        [1.7919],\n",
      "        [1.7463],\n",
      "        [2.3272],\n",
      "        [1.7462],\n",
      "        [1.2762],\n",
      "        [1.8407]])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 84>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m t1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     83\u001b[0m t2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m t1_g \u001b[38;5;241m=\u001b[39m \u001b[43mt1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m t2_g \u001b[38;5;241m=\u001b[39m t2\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(t1_g)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# print(torch.__version__)\n",
    "\n",
    "tensor = torch.tensor([[[1,1,1],[2,2,2],[3,3,3]],[[4,4,4],[5,5,5],[6,6,6]]])\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)\n",
    "print(tensor)\n",
    "\n",
    "#Reshaping a Tensor\n",
    "print(\"Reshaping\")\n",
    "print(tensor.reshape(6,3))\n",
    "print()\n",
    "\n",
    "#Viewing - Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "print(\"Viewing\")\n",
    "x = tensor.view(18)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "#Stacking\n",
    "print(\"Stacking\")\n",
    "x = torch.stack((torch.tensor([1,2,3]),torch.tensor([4,5,6])))\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "#Squeeze - Returns a tensor with all specified dimensions of input of size 1 is removed.\n",
    "print(\"Squeeze\")\n",
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "print(x.size())\n",
    "y = torch.squeeze(x)\n",
    "print(y.size())\n",
    "y = torch.squeeze(x, 3) #Checks for size 1 only at index 3\n",
    "print(y.size())\n",
    "print()\n",
    "\n",
    "#Unsqueezing - Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "print(\"Unsqueeze\")\n",
    "x = torch.zeros(2,2)\n",
    "print(x)\n",
    "print(torch.unsqueeze(x, 0))\n",
    "\n",
    "#Permute - Returns a view of the original tensor input with its dimensions permuted.\n",
    "print(\"Permute\")\n",
    "y = torch.permute(tensor,dims=(1,2,0))\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "#Indexing a tensor\n",
    "print(\"Indexing\")\n",
    "print(tensor[1])\n",
    "print(tensor[1][0])\n",
    "print(tensor[1][0][1])\n",
    "\n",
    "#Converting Tensors to numpy arrays\n",
    "import numpy as np\n",
    "x = torch.tensor([[1,1,1],[1,1,1]])\n",
    "print(x)\n",
    "num = np.array(x)\n",
    "print(num)\n",
    "num = num.reshape(3,2)\n",
    "y = torch.tensor(num)\n",
    "print(y)\n",
    "\n",
    "print()\n",
    "#Random Tensor\n",
    "random_tensor = torch.rand((7,7))\n",
    "print(\"Tensor 1 for multiplication: \")\n",
    "print(random_tensor)\n",
    "\n",
    "#Multiplication of 2 random tensors\n",
    "rand_2 = torch.rand(1,7)\n",
    "print(\"Tensor 2 for multiplication: \")\n",
    "print(rand_2)\n",
    "mul = random_tensor @ rand_2.T\n",
    "print(\"After multiplication: \")\n",
    "print(mul)\n",
    "\n",
    "import torch\n",
    "\n",
    "#Create 2 random tensors of size (2,3) and send them to GPU\n",
    "t1 = torch.rand(2,3)\n",
    "t2 = torch.rand(2,3)\n",
    "t1_g = t1.to(\"cuda\")\n",
    "t2_g = t2.to(\"cuda\")\n",
    "print(t1_g)\n",
    "print(t2_g)\n",
    "\n",
    "#Perform Matrix multiplication\n",
    "tmul = torch.matmul(t1_g,t2_g.T)\n",
    "print(tmul)\n",
    "\n",
    "#Get max and min values of the 2 random tensors\n",
    "print(t1_g.max(),t2_g.max())\n",
    "print(t1_g.min(),t2_g.min())\n",
    "\n",
    "#Get max and min index values of the 2 random tensors\n",
    "print(t1_g.argmax(),t2_g.argmax())\n",
    "print(t1_g.argmin(),t2_g.argmin())\n",
    "\n",
    "#Random tensor with shape(1,1,1,10) and remove all dimensions with shape 1\n",
    "t3 = torch.rand(1,1,1,10)\n",
    "print(t3.shape)\n",
    "t3 = torch.squeeze(t3)\n",
    "print(t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bee8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
