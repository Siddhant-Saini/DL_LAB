{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b11366b-8de7-49f3-be4e-694521662b3e",
   "metadata": {},
   "source": [
    "## Q1 \n",
    "Implement two layer Feed Forward Neural Network for XOR Logic Gate with 2-bit Binary \n",
    "Input using Sigmoid activation. Verify the number of learnable parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec795530-645a-4e60-aee4-09f74029f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XORModel(\n",
      "  (linear1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (activation1): Sigmoid()\n",
      "  (linear2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1000/10000, Loss = 0.27266925573349\n",
      "Epoch 2000/10000, Loss = 0.27059854939579964\n",
      "Epoch 3000/10000, Loss = 0.26853587478399277\n",
      "Epoch 4000/10000, Loss = 0.2639296129345894\n",
      "Epoch 5000/10000, Loss = 0.22337761893868446\n",
      "Epoch 6000/10000, Loss = 0.0001427828324267466\n",
      "Epoch 7000/10000, Loss = 1.2214229627716122e-11\n",
      "Epoch 8000/10000, Loss = 3.1867841698840493e-12\n",
      "Epoch 9000/10000, Loss = 3.1867841698840493e-12\n",
      "Epoch 10000/10000, Loss = 3.1867841698840493e-12\n",
      "9\n",
      "Input =  tensor([0., 1.])\n",
      "Output =  tensor([1.0000], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21ae19871c0>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "loss_list = []\n",
    "torch.manual_seed(42)\n",
    "\n",
    "x = torch.tensor([[0,0],[0,1],[1,0],[1,1]],dtype=torch.float32)\n",
    "y = torch.tensor([0,1,1,0],dtype=torch.float32)\n",
    "\n",
    "class XORModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORModel,self).__init__()\n",
    "        self.linear1 = nn.Linear(2,2,bias = True)\n",
    "        self.activation1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(2,1,bias = True)\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "        \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx].to(device),self.Y[idx].to(device)\n",
    "\n",
    "dataset = MyDataset(x,y)\n",
    "batch_size = 1\n",
    "train_data_loader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = XORModel().to(device)\n",
    "print(model)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.03)\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    totalloss = 0\n",
    "    for i,data in enumerate(train_data_loader):\n",
    "        inputs,labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.flatten(),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        totalloss += loss.item()\n",
    "    return totalloss/(len(train_data_loader)*batch_size)\n",
    "\n",
    "EPOCHS = 10000\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "    loss_list.append(avg_loss)\n",
    "    if epoch%1000 == 0:\n",
    "        print(f\"Epoch {epoch}/{EPOCHS}, Loss = {avg_loss}\")\n",
    "        \n",
    "total_params = 0\n",
    "for name,param in model.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "print(total_params)\n",
    "\n",
    "input = torch.tensor([0.,1.]).to(device)\n",
    "model.eval()\n",
    "print(\"Input = \",input)\n",
    "print(\"Output = \",model(input))\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad250e7c-265a-4456-bbfe-30e924d83051",
   "metadata": {},
   "source": [
    "## Q3\n",
    "Manually verify the output values by taking system generated values of weights and biases \n",
    "for both Linear1 and Linear2 layers for Qn 1 and apply the transformations to input X and \n",
    "implement the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1213ca-f1c7-489c-af14-ef8f2a561ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9638493619367495\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "linear1w11 = -1.9767\n",
    "linear1w12 = 2.0750\n",
    "linear1w21 = -3.0809\n",
    "linear1w22 = 3.3435\n",
    "linear1b1 = 0.7012\n",
    "linear1b2 = -2.5002\n",
    "\n",
    "linear2w1 = -2.6653\n",
    "linear2w2 = 2.7713\n",
    "linear2b = 1.5715\n",
    "\n",
    "x1 = 0.0\n",
    "x2 = 1.0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "y1 = linear1w11*x1 + linear1w21*x2 + linear1b1\n",
    "y2 = linear1w12*x1 + linear1w22*x2 + linear1b2\n",
    "\n",
    "z1 = sigmoid(y1)\n",
    "z2 = sigmoid(y2)\n",
    "\n",
    "output = linear2w1*z1 + linear2w2*z2 + linear2b\n",
    "print(sigmoid(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b1b3e-660b-40a2-88de-f4fd1e7a9533",
   "metadata": {},
   "source": [
    "## Q2\n",
    "Implement two layer Feed Forward Neural Network for XOR Logic Gate with 2-bit Binary \n",
    "Input using RELU activation. Verify the number of learnable parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39f24b0-b20b-4863-bcab-112214c50822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XORModel(\n",
      "  (linear1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (activation1): ReLU()\n",
      "  (linear2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1000/10000, Loss = 0.13272927916636945\n",
      "Epoch 2000/10000, Loss = 0.13223592318536248\n",
      "Epoch 3000/10000, Loss = 0.13247996004338347\n",
      "Epoch 4000/10000, Loss = 0.1327332718087746\n",
      "Epoch 5000/10000, Loss = 0.13250785483069194\n",
      "Epoch 6000/10000, Loss = 0.13288502063369378\n",
      "Epoch 7000/10000, Loss = 0.1327285693361091\n",
      "Epoch 8000/10000, Loss = 0.13273427389120585\n",
      "Epoch 9000/10000, Loss = 0.13277524875229574\n",
      "Epoch 10000/10000, Loss = 0.13280245118949097\n",
      "Input =  tensor([0., 1.])\n",
      "Output =  tensor([0.9926], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21ae1aa9190>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "loss_list = []\n",
    "torch.manual_seed(42)\n",
    "\n",
    "x = torch.tensor([[0,0],[0,1],[1,0],[1,1]],dtype=torch.float32)\n",
    "y = torch.tensor([0,1,1,0],dtype=torch.float32)\n",
    "\n",
    "class XORModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORModel,self).__init__()\n",
    "        self.linear1 = nn.Linear(2,2,bias = True)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2,1,bias = True)\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "        \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx].to(device),self.Y[idx].to(device)\n",
    "\n",
    "dataset = MyDataset(x,y)\n",
    "batch_size = 1\n",
    "train_data_loader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = XORModel().to(device)\n",
    "print(model)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.03)\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    totalloss = 0\n",
    "    for i,data in enumerate(train_data_loader):\n",
    "        inputs,labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.flatten(),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        totalloss += loss.item()\n",
    "    return totalloss/(len(train_data_loader)*batch_size)\n",
    "\n",
    "EPOCHS = 10000\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "    loss_list.append(avg_loss)\n",
    "    if epoch%1000 == 0:\n",
    "        print(f\"Epoch {epoch}/{EPOCHS}, Loss = {avg_loss}\")\n",
    "\n",
    "input = torch.tensor([0.,1.]).to(device)\n",
    "model.eval()\n",
    "print(\"Input = \",input)\n",
    "print(\"Output = \",model(input))\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab87805-7b8f-4c91-a5c1-a727dc9e2bdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.286\n",
      "[1,   200] loss: 2.248\n",
      "[1,   300] loss: 2.186\n",
      "[1,   400] loss: 2.078\n",
      "[1,   500] loss: 1.897\n",
      "[1,   600] loss: 1.633\n",
      "[1,   700] loss: 1.331\n",
      "[1,   800] loss: 1.061\n",
      "[1,   900] loss: 0.896\n",
      "[1,  1000] loss: 0.770\n",
      "[1,  1100] loss: 0.687\n",
      "[1,  1200] loss: 0.626\n",
      "[2,   100] loss: 0.597\n",
      "[2,   200] loss: 0.546\n",
      "[2,   300] loss: 0.534\n",
      "[2,   400] loss: 0.523\n",
      "[2,   500] loss: 0.463\n",
      "[2,   600] loss: 0.490\n",
      "[2,   700] loss: 0.447\n",
      "[2,   800] loss: 0.421\n",
      "[2,   900] loss: 0.413\n",
      "[2,  1000] loss: 0.415\n",
      "[2,  1100] loss: 0.416\n",
      "[2,  1200] loss: 0.396\n",
      "[3,   100] loss: 0.393\n",
      "[3,   200] loss: 0.382\n",
      "[3,   300] loss: 0.383\n",
      "[3,   400] loss: 0.370\n",
      "[3,   500] loss: 0.360\n",
      "[3,   600] loss: 0.364\n",
      "[3,   700] loss: 0.358\n",
      "[3,   800] loss: 0.349\n",
      "[3,   900] loss: 0.374\n",
      "[3,  1000] loss: 0.345\n",
      "[3,  1100] loss: 0.341\n",
      "[3,  1200] loss: 0.342\n",
      "[4,   100] loss: 0.330\n",
      "[4,   200] loss: 0.316\n",
      "[4,   300] loss: 0.337\n",
      "[4,   400] loss: 0.319\n",
      "[4,   500] loss: 0.318\n",
      "[4,   600] loss: 0.327\n",
      "[4,   700] loss: 0.342\n",
      "[4,   800] loss: 0.317\n",
      "[4,   900] loss: 0.306\n",
      "[4,  1000] loss: 0.330\n",
      "[4,  1100] loss: 0.312\n",
      "[4,  1200] loss: 0.316\n",
      "[5,   100] loss: 0.303\n",
      "[5,   200] loss: 0.292\n",
      "[5,   300] loss: 0.298\n",
      "[5,   400] loss: 0.298\n",
      "[5,   500] loss: 0.296\n",
      "[5,   600] loss: 0.279\n",
      "[5,   700] loss: 0.322\n",
      "[5,   800] loss: 0.306\n",
      "[5,   900] loss: 0.290\n",
      "[5,  1000] loss: 0.297\n",
      "[5,  1100] loss: 0.273\n",
      "[5,  1200] loss: 0.285\n",
      "[6,   100] loss: 0.289\n",
      "[6,   200] loss: 0.281\n",
      "[6,   300] loss: 0.267\n",
      "[6,   400] loss: 0.273\n",
      "[6,   500] loss: 0.279\n",
      "[6,   600] loss: 0.289\n",
      "[6,   700] loss: 0.274\n",
      "[6,   800] loss: 0.262\n",
      "[6,   900] loss: 0.275\n",
      "[6,  1000] loss: 0.251\n",
      "[6,  1100] loss: 0.276\n",
      "[6,  1200] loss: 0.251\n",
      "Finished Training. Final loss = 0.21337981522083282, Total params = 89610\n",
      "Correct = 9269, Total = 10000\n",
      "Accuracy:0.9269000291824341\n",
      "[959, 0, 12, 1, 1, 8, 14, 4, 4, 10]\n",
      "[0, 1112, 6, 1, 2, 4, 3, 8, 9, 9]\n",
      "[4, 3, 936, 22, 3, 5, 5, 26, 7, 1]\n",
      "[2, 2, 13, 940, 2, 45, 0, 6, 28, 12]\n",
      "[0, 0, 12, 0, 912, 9, 15, 6, 9, 29]\n",
      "[4, 1, 0, 11, 0, 771, 14, 1, 18, 8]\n",
      "[6, 3, 12, 2, 11, 10, 901, 0, 11, 1]\n",
      "[3, 2, 11, 16, 3, 4, 1, 950, 7, 20]\n",
      "[2, 12, 24, 12, 4, 29, 5, 2, 873, 4]\n",
      "[0, 0, 6, 5, 44, 7, 0, 25, 8, 915]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class DeepFFClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(784,100,bias=True),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(100,100,bias=True),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(100,10,bias=True),\n",
    "                                )\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 784)\n",
    "        return self.net(x)\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepFFClassifier().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "mat = [[0 for _ in range(10)] for _ in range(10)]\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "\n",
    "    for i in range(len(predicted)):\n",
    "        mat[predicted[i].item()][tlabels[i].item()] += 1\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")\n",
    "accuracy=correct/total\n",
    "print(\"Accuracy:{}\".format(accuracy))\n",
    "for i in range(10):\n",
    "    print(mat[i])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ffd353-3a98-4498-8f86-99fd49321fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[959, 0, 12, 1, 1, 8, 14, 4, 4, 10]\n",
      "[0, 1112, 6, 1, 2, 4, 3, 8, 9, 9]\n",
      "[4, 3, 936, 22, 3, 5, 5, 26, 7, 1]\n",
      "[2, 2, 13, 940, 2, 45, 0, 6, 28, 12]\n",
      "[0, 0, 12, 0, 912, 9, 15, 6, 9, 29]\n",
      "[4, 1, 0, 11, 0, 771, 14, 1, 18, 8]\n",
      "[6, 3, 12, 2, 11, 10, 901, 0, 11, 1]\n",
      "[3, 2, 11, 16, 3, 4, 1, 950, 7, 20]\n",
      "[2, 12, 24, 12, 4, 29, 5, 2, 873, 4]\n",
      "[0, 0, 6, 5, 44, 7, 0, 25, 8, 915]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(mat[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d169423-d556-441e-a166-b42774e762f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
