{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b20dee0-bb14-4c0b-a8cb-e6121ceb2efe",
   "metadata": {},
   "source": [
    "## Q1\n",
    "For the following training data, build a linear regression model. Assume w and b are\n",
    "initialized with 1 and learning parameter is set to 0.001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704b6fd7-6b15-48b8-aade-7b5c8463eb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bd2af45580>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = torch.tensor([12.4,14.3,14.5,14.9,16.1,16.9,16.5,15.4,17.0,17.9,18.8,20.3,22.4,19.4,15.5,16.7,17.3,18.4,19.2,17.4,19.5,19.7,21.2])\n",
    "y = torch.tensor([11.2,12.5,12.7,13.1,14.1,14.8,14.4,13.4,14.9,15.6,16.4,17.7,19.6,16.9,14.0,14.6,15.1,16.1,16.8,15.2,17.0,17.2,18.6])\n",
    "b = torch.rand([1],requires_grad = True)\n",
    "w = torch.rand([1],requires_grad = True)\n",
    "learning_rate = torch.tensor(0.001)\n",
    "loss_list = []\n",
    "\n",
    "for epochs in range(100):\n",
    "    loss = 0.0\n",
    "    for j in range(len(x)):\n",
    "        a = w*x[j]\n",
    "        y_p = a + b\n",
    "        loss += (y[j] - y_p)**2\n",
    "    loss = loss/len(x)\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        b -= learning_rate*b.grad\n",
    "\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a3148-ac91-47e1-8021-04c4236e0232",
   "metadata": {},
   "source": [
    "## Q2\n",
    "Find the value of w.grad, b.grad using analytical solution for the given linear regression \n",
    "problem. Initial value of w = b =1. Learning parameter is set to 0.001. Implement the same \n",
    "and verify the values of w.grad , b.grad and updated parameter values for two epochs. \n",
    "Consider the difference between predicted and target values of y is defined as (yp-y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7ae38b-678c-4a58-91d7-8782d264b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-174.) tensor(-52.)\n",
      "w = 1.1740000247955322,b = 1.0520000457763672,loss = 757.0\n",
      "tensor(-170.2080) tensor(-50.8520)\n",
      "w = 1.344208002090454,b = 1.1028521060943604,loss = 724.3797607421875\n",
      "Analytical Solution\n",
      "w = 0.79,b = 0.9299999999999999,loss = 757.0\n",
      "w = 0.57454,b = 0.8581799999999999,loss = 797.7140999999999\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inp_x = np.array([2,4])\n",
    "inp_y = np.array([20,40])\n",
    "\n",
    "x = torch.tensor(inp_x)\n",
    "y = torch.tensor(inp_y)\n",
    "b = torch.tensor(1.,requires_grad = True)\n",
    "w = torch.tensor(1.,requires_grad = True)\n",
    "learning_rate = torch.tensor(0.001)\n",
    "loss_list = []\n",
    "\n",
    "for epochs in range(2):\n",
    "    loss = 0.0\n",
    "    for j in range(len(x)):\n",
    "        a = w*x[j]\n",
    "        y_p = a + b\n",
    "        loss += (y[j] - y_p)**2\n",
    "    loss = loss/len(x)\n",
    "    loss_list.append(loss.item())\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        b -= learning_rate*b.grad\n",
    "    \n",
    "    print(w.grad,b.grad)\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    print(\"w = {},b = {},loss = {}\".format(w,b,loss))\n",
    "\n",
    "def analytical(x,y,w,b):  \n",
    "    for epochs in range(2):\n",
    "        loss = 0.0\n",
    "        for j in range(len(x)):\n",
    "            y_p = w*x[j] + b\n",
    "            loss += (y[j] - y_p)**2\n",
    "        loss = loss/len(x)\n",
    "        wgrad,bgrad = 0,0\n",
    "        for i in range(len(x)):\n",
    "            wgrad += (y[j]-y_p)*(x[i])\n",
    "            bgrad += (y[j]-y_p)\n",
    "        w -= 0.001*wgrad*2/len(x)\n",
    "        b -= 0.001*bgrad*2/len(x)\n",
    "        print(\"w = {},b = {},loss = {}\".format(w,b,loss))\n",
    "\n",
    "print(\"Analytical Solution\")\n",
    "analytical(inp_x,inp_y,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cb4cb-50de-4eca-b725-9044579a8017",
   "metadata": {},
   "source": [
    "## Q3\n",
    "Revise the linear regression model by defining a user defined class titled RegressionModel\n",
    "with two parameters w and b as its member variables. Define a constructor to initialize w \n",
    "and b with value 1. Define four member functions namely forward(x) to implement wx+b, \n",
    "update() to update w and b values, reset_grad() to reset parameters to zero, criterion(y, yp) \n",
    "to implement MSE Loss given the predicted y value yp and the target label y. Define an \n",
    "object of this class named model and invoke all the methods. Plot the graph of epoch vs \n",
    "loss by varying epoch to 100 iterations. \n",
    "x = torch.tensor([5.0, 7.0, 12.0, 16.0, 20.0])\n",
    "y = torch.tensor([40.0, 120.0, 180.0, 210.0, 240.0])\n",
    "learning_rate = torch.tensor(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb898c8-a129-4493-803a-618e05e7c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters are w=tensor([12.8820], requires_grad=True),b=tensor([1.6951], requires_grad=True), and loss =482.8441467285156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bd2c0289a0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.tensor([5.0,7.0,12.0,16.0,20.0])\n",
    "y = torch.tensor([40.0,120.0,180.0,210.0,240.0])\n",
    "learning_rate = torch.tensor(0.001)\n",
    "\n",
    "class RegressionModel:\n",
    "    def __init__(self):\n",
    "        self.w = torch.rand([1],requires_grad = True)\n",
    "        self.b = torch.rand([1],requires_grad = True)\n",
    "    def forward(self,x):\n",
    "        return self.w*x + self.b\n",
    "    def update(self):\n",
    "        self.w -= learning_rate*self.w.grad\n",
    "        self.b -= learning_rate*self.b.grad\n",
    "    def reset_grad(self):\n",
    "        self.w.grad.zero_()\n",
    "        self.b.grad.zero_()\n",
    "\n",
    "def criterion(yj,y_p):\n",
    "    return (yj - y_p)**2\n",
    "\n",
    "model = RegressionModel()\n",
    "loss_list = []\n",
    "\n",
    "for epochs in range(100):\n",
    "    loss = 0.0\n",
    "    for j in range(len(x)):\n",
    "        y_p = model.forward(x[j])\n",
    "        loss += criterion(y[j],y_p)\n",
    "    loss = loss/len(x)\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.update()\n",
    "    model.reset_grad()\n",
    "\n",
    "print(\"The parameters are w={},b={}, and loss ={}\".format(model.w,model.b,loss.item()))\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15886bfb-0cd1-42f6-801b-7cfd4d4eb574",
   "metadata": {},
   "source": [
    "## Q4\n",
    "Convert your program written in Qn 3 to extend nn.module in your model. Also override \n",
    "the necessary methods to fit the regression line. Illustrate the use of Dataset and DataLoader\n",
    "from torch.utils.data in your implementation. Use the SGD Optimizer torch.optim.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4208e5-cb7b-4063-ac17-6023d19a6df6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters are w=13.340835571289062,b=4.587327480316162, and loss =1980.3292236328125\n",
      "3960.658447265625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bd2dc9fcd0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.Y[idx]\n",
    "\n",
    "x = torch.tensor([5.0,7.0,12.0,16.0,20.0])\n",
    "y = torch.tensor([40.0,120.0,180.0,210.0,240.0])\n",
    "dataset = MyDataset(x,y)\n",
    "data_loader = DataLoader(dataset,batch_size=4,shuffle=True)\n",
    "    \n",
    "learning_rate = torch.tensor(0.001)\n",
    "\n",
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = torch.nn.Parameter(torch.rand([1],requires_grad = True))\n",
    "        self.b = torch.nn.Parameter(torch.rand([1],requires_grad = True))\n",
    "    def forward(self,x):\n",
    "        return self.w*x + self.b\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "model = RegressionModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.003)\n",
    "\n",
    "for epochs in range(100):\n",
    "    loss = 0.0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        inputs,labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss += loss.item()\n",
    "    finalloss = loss/len(data_loader)*4\n",
    "\n",
    "print(\"The parameters are w={},b={}, and loss ={}\".format(model.w.item(),model.b.item(),loss.item()))\n",
    "\n",
    "    \n",
    "print(finalloss.item())\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b998de-5909-4627-919f-51f61d1c04a7",
   "metadata": {},
   "source": [
    "## Q5\n",
    "Use PyTorch’s nn.Linear() in your implementation to perform linear regression for the data \n",
    "provided in Qn. 1. Also plot the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4b2b7f-ebe8-406f-8e0c-7907008db186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =39.035831451416016\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(torch.tensor([12.4,14.3,14.5,14.9,16.1,16.9,16.5,15.4,17.0,17.9,18.8,20.3,22.4,19.4,15.5,16.7,17.3,18.4,19.2,17.4,19.5,19.7,21.2]))\n",
    "y = Variable(torch.tensor([11.2,12.5,12.7,13.1,14.1,14.8,14.4,13.4,14.9,15.6,16.4,17.7,19.6,16.9,14.0,14.6,15.1,16.1,16.8,15.2,17.0,17.2,18.6]))\n",
    "\n",
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(23, 23)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = RegressionModel()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0032)\n",
    "\n",
    "for epochs in range(100):\n",
    "    pred_y = model(x)\n",
    "    loss = criterion(pred_y, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"loss ={}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5f7f9-e09a-4612-83b0-499c28c6b03a",
   "metadata": {},
   "source": [
    "## Q6\n",
    "Implement multiple linear regression for the data provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d8c406-9299-42a3-9ddf-f3775069d17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3, 4]), tensor([8, 5]), tensor([-3.5000,  3.5000])]\n",
      "[tensor([5, 6]), tensor([7, 3]), tensor([ 2.5000, 11.5000])]\n",
      "[tensor([2]), tensor([1]), tensor([5.7000])]\n",
      "After 0 epochs, The parameters are w=Parameter containing:\n",
      "tensor([0.3043], requires_grad=True),b=Parameter containing:\n",
      "tensor([0.0978], requires_grad=True), and loss =Parameter containing:\n",
      "tensor([0.4534], requires_grad=True)\n",
      "After 33 epochs, The parameters are w=Parameter containing:\n",
      "tensor([1.4453], requires_grad=True),b=Parameter containing:\n",
      "tensor([-0.6997], requires_grad=True), and loss =Parameter containing:\n",
      "tensor([0.6430], requires_grad=True)\n",
      "After 66 epochs, The parameters are w=Parameter containing:\n",
      "tensor([1.9986], requires_grad=True),b=Parameter containing:\n",
      "tensor([-1.0907], requires_grad=True), and loss =Parameter containing:\n",
      "tensor([0.7574], requires_grad=True)\n",
      "After 99 epochs, The parameters are w=Parameter containing:\n",
      "tensor([2.2881], requires_grad=True),b=Parameter containing:\n",
      "tensor([-1.3188], requires_grad=True), and loss =Parameter containing:\n",
      "tensor([0.8266], requires_grad=True)\n",
      "tensor(1.0576, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,X1,X2,Y):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X1[idx],self.X2[idx],self.Y[idx]\n",
    "\n",
    "x1 = torch.tensor([3,4,5,6,2])\n",
    "x2 = torch.tensor([8,5,7,3,1])\n",
    "y = torch.tensor([-3.5,3.5,2.5,11.5,5.7])\n",
    "dataset = MyDataset(x1,x2,y)\n",
    "data_loader = DataLoader(dataset,batch_size=2,shuffle=True)\n",
    "\n",
    "for data in iter(data_loader):\n",
    "    print(data)\n",
    "\n",
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1 = torch.nn.Parameter(torch.rand([1],requires_grad = True))\n",
    "        self.w2 = torch.nn.Parameter(torch.rand([1],requires_grad = True))\n",
    "        self.b = torch.nn.Parameter(torch.rand([1],requires_grad = True))\n",
    "    def forward(self,x1,x2):\n",
    "        return self.w1*x1 + self.w2*x2 + self.b\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "model = RegressionModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001)\n",
    "\n",
    "for epochs in range(100):\n",
    "    loss = 0.0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        x1,x2,labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x1,x2)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss += loss.item()\n",
    "\n",
    "    if epochs%33==0:\n",
    "        print(\"After {} epochs, The parameters are w={},b={}, and loss ={}\".format(epochs, model.w1,model.w2,model.b,loss.item()))\n",
    "\n",
    "    finalloss = loss/len(data_loader)*4\n",
    "\n",
    "print(finalloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788fb00d-b7bd-4161-84b6-3b012d57d769",
   "metadata": {},
   "source": [
    "## Q7\n",
    "Implement logistic regression \n",
    "x = [1, 5, 10, 10, 25, 50, 70, 75, 100,]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804a5bc8-0bff-49ac-bce6-b556899a5df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 epochs, The parameters are w=Parameter containing:\n",
      "tensor([0.2918], requires_grad=True),b=Parameter containing:\n",
      "tensor([0.3257], requires_grad=True), and loss =0.0\n",
      "After 33 epochs, The parameters are w=Parameter containing:\n",
      "tensor([0.0396], requires_grad=True),b=Parameter containing:\n",
      "tensor([0.2318], requires_grad=True), and loss =0.035689886659383774\n",
      "After 66 epochs, The parameters are w=Parameter containing:\n",
      "tensor([0.0409], requires_grad=True),b=Parameter containing:\n",
      "tensor([0.1484], requires_grad=True), and loss =0.03390238806605339\n",
      "After 99 epochs, The parameters are w=Parameter containing:\n",
      "tensor([0.0421], requires_grad=True),b=Parameter containing:\n",
      "tensor([0.0672], requires_grad=True), and loss =0.032211825251579285\n",
      "tensor(0.0143, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.Y[idx]\n",
    "\n",
    "x = torch.tensor([1,5,10,10,25,50,70,75,100])\n",
    "y = torch.tensor([0,0,0,0,0,1,1,1,1])\n",
    "dataset = MyDataset(x,y)\n",
    "data_loader = DataLoader(dataset,batch_size=1,shuffle=False)\n",
    "\n",
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = torch.nn.Parameter(torch.rand([1],requires_grad = True))\n",
    "        self.b = torch.nn.Parameter(torch.rand([1],requires_grad = True))\n",
    "    def forward(self,x):\n",
    "        return self.w*x + self.b\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "model = RegressionModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001)\n",
    "\n",
    "for epochs in range(100):\n",
    "    loss = 0.0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        inputs,labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        outputs = sigmoid(outputs)\n",
    "        labels = labels.to(torch.float32)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss.item()\n",
    "\n",
    "    if epochs%33==0:\n",
    "        print(\"After {} epochs, The parameters are w={},b={}, and loss ={}\".format(epochs, model.w,model.b,loss.item()))\n",
    "\n",
    "    finalloss = loss/len(data_loader)*4\n",
    "\n",
    "print(finalloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9d13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
